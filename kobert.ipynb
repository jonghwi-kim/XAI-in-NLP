{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /workspace/LIME/.cache/kobert_v1.zip\n",
      "using cached model. /workspace/LIME/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import random\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import train_test_split                                                      \n",
    "\n",
    "\n",
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "#transformers\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "#GPU 사용\n",
    "device = torch.device(\"cuda:0\")\n",
    "#BERT 모델, Vocabulary 불러오기\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "DATA = \"steam\"\n",
    "\n",
    "train_writer = SummaryWriter('./runs/' + DATA +'/LIME/train')\n",
    "valid_writer = SummaryWriter('./runs/' + DATA +'/LIME/valid')\n",
    "test_writer = SummaryWriter('./runs/' + DATA +'/LIME/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 확인 : \n",
      " sentence    0\n",
      "label       0\n",
      "dtype: int64\n",
      "중복값 체크 :  0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "steam=pd.DataFrame()\n",
    "sentences=[]\n",
    "labels=[]\n",
    "\n",
    "file = open(\"/workspace/data/steam.txt\", \"r\")\n",
    "for line in file:\n",
    "    lines=line.split('\\t')\n",
    "    labels.append(int(lines[0]))\n",
    "    sentences.append(lines[1].strip('\\n'))\n",
    "\n",
    "steam['sentence']=sentences\n",
    "steam['label']=labels\n",
    "\n",
    "print('결측치 확인 : \\n', steam.isnull().sum())\n",
    "print('중복값 체크 : ', steam.duplicated().sum(), '\\n')\n",
    "\n",
    "train, test = train_test_split(steam, test_size=0.1, random_state=seed) #훈련데이터 셋\n",
    "\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "test.to_csv(\"/workspace/data/steam_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "for sentence, label in zip(train['sentence'], train['label']):\n",
    "    train_data.append([sentence, label])\n",
    "\n",
    "train_data, validation_data = train_test_split(train_data, test_size=0.1, random_state=seed) #훈련데이터 셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /workspace/LIME/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed) # torch \n",
    "torch.cuda.manual_seed(seed)# torch \n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "\n",
    "max_len = 128\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 2000\n",
    "learning_rate = 5e-5\n",
    "\n",
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "train_data = BERTDataset(train_data, 0, 1, tok, max_len, True, False) #train_data 리스트 0번째가 sent / 1은 label\n",
    "validation_data = BERTDataset(validation_data, 0, 1, tok, max_len, True, False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=5)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, num_workers=5)\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "        with open('/workspace/LIME/.cache/kobert_from_pretrained/config.json') as f:\n",
    "            json_object = json.load(f)\n",
    "        #self.config = Config(json_object)\n",
    "        #self.base_model_prefix = \"bert\"\n",
    "        \n",
    "        #self.device = device\n",
    "        #self.get_input_embeddings = bertmodel.get_input_embeddings()\n",
    "        \n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "\n",
    "#        return pooler\n",
    "        return self.classifier(out)\n",
    "\n",
    "#BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "\n",
    "#optimizer와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#loss_fn = nn.BCEWithLogitsLoss()\n",
    "#loss_fn = nn.BCELoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):#out,label\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1266 [00:00<18:30,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 0.7243950366973877 train acc 0.453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1266/1266 [15:09<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 0.439706951379776 train acc 0.7361176935229068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:30<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 0.5037440657615662 test acc 0.8047429078014184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1266 [00:00<17:18,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 0.5187364816665649 train acc 0.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1266/1266 [13:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 loss 0.3356657922267914 train acc 0.8229314770932069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:31<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 loss 0.6023536920547485 test acc 0.8175531914893618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1266 [00:00<17:15,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 0.46257078647613525 train acc 0.828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1266/1266 [13:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 loss 0.23815187811851501 train acc 0.8757726105845183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:30<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 loss 0.7942685484886169 test acc 0.8072473404255319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1266 [00:00<16:53,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.3701239228248596 train acc 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1266/1266 [13:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 loss 0.2112838476896286 train acc 0.9122111966824644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:30<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 loss 0.640751302242279 test acc 0.8206338652482269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1266 [00:00<17:19,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.1703774333000183 train acc 0.921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1266/1266 [13:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 loss 0.08035454154014587 train acc 0.9387021129541864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:30<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 loss 0.7035333514213562 test acc 0.80489804964539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1266 [00:00<17:15,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 0.2520228624343872 train acc 0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1266/1266 [13:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 loss 0.13940569758415222 train acc 0.9587702409162716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:30<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 loss 0.8322716951370239 test acc 0.8194370567375887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1266 [00:00<17:50,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 0.06636637449264526 train acc 0.984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1266/1266 [13:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 loss 0.17753219604492188 train acc 0.9720181674565561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:30<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 loss 1.0882468223571777 test acc 0.8231382978723404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1266 [00:00<16:44,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1 loss 0.010313128121197224 train acc 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1266/1266 [13:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 loss 0.005790011025965214 train acc 0.9790679304897314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:30<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 loss 1.060509204864502 test acc 0.8216533687943263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1266 [00:00<18:19,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch id 1 loss 0.1356198787689209 train acc 0.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1266/1266 [13:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 loss 0.0032052528113126755 train acc 0.9845601303317536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:30<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 loss 1.1889140605926514 test acc 0.8226285460992907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1266 [00:00<16:51,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch id 1 loss 0.004487995989620686 train acc 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1266/1266 [13:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 loss 0.047393057495355606 train acc 0.9872432859399684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:30<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 loss 1.2317899465560913 test acc 0.822406914893617\n"
     ]
    }
   ],
   "source": [
    "model_result=[]\n",
    "#train_loss_list = []\n",
    "#train_acc_list = []\n",
    "#valid_loss_list = []\n",
    "#valid_acc_list = []\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed) # torch \n",
    "torch.cuda.manual_seed(seed)# torch \n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length = valid_length\n",
    "\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()    \n",
    "        scheduler.step()    #Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "\n",
    "    print(\"epoch {} loss {} train acc {}\".format(e+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    train_writer.add_scalar(\"Loss/train\", loss.data.cpu().numpy(), e+1)\n",
    "    train_writer.add_scalar(\"Accuracy/train\", train_acc/(batch_id+1), e+1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(valid_dataloader)):\n",
    "            token_ids = token_ids.long().to(device)\n",
    "            segment_ids = segment_ids.long().to(device)\n",
    "            valid_length= valid_length\n",
    "            label = label.long().to(device)\n",
    "            \n",
    "            out = model(token_ids, valid_length, segment_ids)\n",
    "            loss2 = loss_fn(out, label)\n",
    "            test_acc += calc_accuracy(out, label)\n",
    "        print(\"epoch {} loss {} test acc {}\".format(e+1, loss2.data.cpu().numpy(), test_acc / (batch_id+1)))\n",
    "        valid_writer.add_scalar(\"Accuracy/valid\", test_acc/(batch_id+1), e+1)\n",
    "        valid_writer.add_scalar(\"Loss/valid\", loss2.data.cpu().numpy(), e+1)\n",
    "\n",
    "        #모델 저장하기\n",
    "        model_path = \"/workspace/model/KoBERT/steam/\" + str(e+1) + \"_0816.pt\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "valid_writer.close()\n",
    "train_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot(y_test , pred_proba_c1):\n",
    "    # 임곗값에 따른 FPR, TPR 값을 반환 받음. \n",
    "    fprs , tprs , thresholds = roc_curve(y_test, pred_proba_c1)\n",
    "\n",
    "    # ROC Curve를 plot 곡선으로 그림. \n",
    "    plt.plot(fprs , tprs, label='ROC')\n",
    "    # 가운데 대각선 직선을 그림. \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "  \n",
    "    # FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등   \n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel('FPR( 1 - Sensitivity )')\n",
    "    plt.ylabel('TPR( Recall )')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /workspace/LIME/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:07<00:00, 78.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch [오류 분석]\n",
      "[[4220  767]\n",
      " [1049 3964]]\n",
      "0.8184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          부정       0.80      0.85      0.82      4987\n",
      "          긍정       0.84      0.79      0.81      5013\n",
      "\n",
      "    accuracy                           0.82     10000\n",
      "   macro avg       0.82      0.82      0.82     10000\n",
      "weighted avg       0.82      0.82      0.82     10000\n",
      "\n",
      "AUC : 81.85\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y=exp_a / sum_exp_a\n",
    "    return y\n",
    "\n",
    "#validation_data\n",
    "true_label=[]\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "dataset_another = []\n",
    "\n",
    "for i, v in zip(test['sentence'], test['label']):\n",
    "    true_label.append(int(v))\n",
    "    data = [i, v]\n",
    "    dataset_another.append(data)\n",
    "\n",
    "another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=1, num_workers=5)\n",
    "\n",
    "roc_auc_list = []\n",
    "\n",
    "for i in range(1):\n",
    "    test_eval=[]\n",
    "    prob = []\n",
    "    #model_path = \"/home/jonghwi/hdd/hdd/model/finance/\" + \"FHB_Kobert_\" + str(i) + \".pt\"\n",
    "\n",
    "    model_path = \"/workspace/model/KoBERT/steam/7_0816.pt\"\n",
    "    #print(model_path)\n",
    "    model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        \n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        soft=out.detach().to(device).cpu().numpy()\n",
    "        a=np.array(list(soft[0]))\n",
    "        a=list(softmax(a))\n",
    "        prob.append(a[1])\n",
    "        test_eval.append(a.index(max(a)))\n",
    "\n",
    "    print(str(i) + ' epoch [오류 분석]')\n",
    "    print(confusion_matrix(true_label,test_eval))\n",
    "    #target_names = ['부정', '중립', '긍정']\n",
    "    target_names = ['부정', '긍정']\n",
    "    acc = accuracy_score(true_label,test_eval)\n",
    "    print(acc)\n",
    "    \n",
    "    print(classification_report(true_label, test_eval, target_names=target_names))\n",
    "    test_writer.add_scalar(\"Accuracy/test\", acc, i)\n",
    "\n",
    "    print('AUC : {:.2f}'.format(roc_auc_score(true_label, test_eval)*100))\n",
    "    roc_curve_plot(true_label, prob)\n",
    "    roc_auc_list.append(roc_auc_score(true_label, test_eval)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fasle Negative :  1049\n",
      "Fasle Positive :  767\n"
     ]
    }
   ],
   "source": [
    "false_negative = []\n",
    "false_positive = []\n",
    "\n",
    "for i in range(len(true_label)):\n",
    "    #print(true_label[i])\n",
    "    #print(test_eval[i])\n",
    "    if (true_label[i] == 1) & (test_eval[i] == 0):\n",
    "        false_negative.append(i)\n",
    "    elif (true_label[i] == 0) & (test_eval[i] == 1):\n",
    "        false_positive.append(i)\n",
    "\n",
    "\n",
    "print('Fasle Negative : ', len(false_negative))\n",
    "print('Fasle Positive : ', len(false_positive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>predicted</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>더럽게싸네 씨벌탱</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>나의 시간이 없어져부려따</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.5로 빠른 패치를 부탁드립니다. 아직도 스팀에서는 17 이여서 효과팩을 구입 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지인 7명에게 추천하고 7명이 접은 게임</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>뭣같은 게임..</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>그냥 그럭저럭</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>돈주고 사기엔 존나 아까운 게임</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>아르마급의 현실적인 고증이 마음에 들지만그다지 전략적이지 못한 플레이가 아쉬운 게임...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>나름에 코스믹호러를 만들어다 하지만 조금 게임이 너무 완성도 약간 낮음</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>좀비몸이 와장창</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1049 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  predicted  true\n",
       "0                                             더럽게싸네 씨벌탱          0     1\n",
       "1                                         나의 시간이 없어져부려따          0     1\n",
       "2     17.5로 빠른 패치를 부탁드립니다. 아직도 스팀에서는 17 이여서 효과팩을 구입 ...          0     1\n",
       "3                                지인 7명에게 추천하고 7명이 접은 게임          0     1\n",
       "4                                              뭣같은 게임..          0     1\n",
       "...                                                 ...        ...   ...\n",
       "1044                                            그냥 그럭저럭          0     1\n",
       "1045                                  돈주고 사기엔 존나 아까운 게임          0     1\n",
       "1046  아르마급의 현실적인 고증이 마음에 들지만그다지 전략적이지 못한 플레이가 아쉬운 게임...          0     1\n",
       "1047            나름에 코스믹호러를 만들어다 하지만 조금 게임이 너무 완성도 약간 낮음          0     1\n",
       "1048                                           좀비몸이 와장창          0     1\n",
       "\n",
       "[1049 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = []\n",
    "predicted = []\n",
    "real = []\n",
    "\n",
    "for i in false_negative:\n",
    "    sentence.append(test.at[i, 'sentence'])\n",
    "    predicted.append(test_eval[i])\n",
    "    real.append(true_label[i])\n",
    "\n",
    "false_negative = pd.DataFrame({\"sentence\":sentence, \"predicted\":predicted, \"true\":real }).reset_index(drop=True)\n",
    "false_negative.to_csv('/workspace/data/false_negative.csv', index=False)\n",
    "false_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>predicted</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>꾸리꾸리한 디자인, 꾸리꾸리한 재미.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.......................호오, 제법이군요? 하지만 제 개돼지력은 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>인터랙션이 있는 괜찮은 비쥬얼 노벨. 홀로 집에 남겨졌을 때의 허전함을 게임을 통해...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>스토리 라인을 매우 흥미롭게 몰입을 하면서 플레이 한다하더라도... 결론은 유비식 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이거 시작하고나서 조금 걸었는데 속이 울렁거려ㅡㅡ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>도전과제 모으는 게임</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>포커 모르면 할 수가 없음 쟤네들이 뭔가 개그를 치는데 거기에 따라갈 수 없음 미안...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>패드를 사용하는데 패드만 인식한다. 마우스로 하려면 패드를 뺴야한다. 하지만 게임은...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>우주에서 하는 마인크래프트를 느겨보세요~</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>야 줠라 재밌네 진짜 플탐 14분</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  predicted  true\n",
       "0                                 꾸리꾸리한 디자인, 꾸리꾸리한 재미.          1     0\n",
       "1    .......................호오, 제법이군요? 하지만 제 개돼지력은 ...          1     0\n",
       "2    인터랙션이 있는 괜찮은 비쥬얼 노벨. 홀로 집에 남겨졌을 때의 허전함을 게임을 통해...          1     0\n",
       "3    스토리 라인을 매우 흥미롭게 몰입을 하면서 플레이 한다하더라도... 결론은 유비식 ...          1     0\n",
       "4                          이거 시작하고나서 조금 걸었는데 속이 울렁거려ㅡㅡ          1     0\n",
       "..                                                 ...        ...   ...\n",
       "762                                        도전과제 모으는 게임          1     0\n",
       "763  포커 모르면 할 수가 없음 쟤네들이 뭔가 개그를 치는데 거기에 따라갈 수 없음 미안...          1     0\n",
       "764  패드를 사용하는데 패드만 인식한다. 마우스로 하려면 패드를 뺴야한다. 하지만 게임은...          1     0\n",
       "765                             우주에서 하는 마인크래프트를 느겨보세요~          1     0\n",
       "766                                 야 줠라 재밌네 진짜 플탐 14분          1     0\n",
       "\n",
       "[767 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = []\n",
    "predicted = []\n",
    "real = []\n",
    "\n",
    "for i in false_positive:\n",
    "    sentence.append(test.at[i, 'sentence'])\n",
    "    predicted.append(test_eval[i])\n",
    "    real.append(true_label[i])\n",
    "\n",
    "false_positive = pd.DataFrame({\"sentence\":sentence, \"predicted\":predicted, \"true\":real }).reset_index(drop=True)\n",
    "false_positive.to_csv('/workspace/data/false_positive.csv', index=False)\n",
    "false_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "import torch\n",
    "from transformers import BertModel, AutoModelForSequenceClassification\n",
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('skt/kobert-base-v1')\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "\n",
    "cls_explainer = SequenceClassificationExplainer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  평가 라아트 노벨 소설 원작인 만큼 라이트 노벨스러운 록맨 파생작 P.S 시궁창아 esc고쳐라 바로꺼지는거 땜에 당황했다\n",
      "속성 :  [('[CLS]', 0.0), ('▁평가', 0.14635605661186182), ('▁라', 0.22927024805838545), ('아트', 0.019300895785065896), ('▁노', 0.1520566394918187), ('벨', 0.08954743335331102), ('▁소설', 0.19635919433195054), ('▁원', 0.22414102394649799), ('작', 0.3079029718231702), ('인', 0.13838169881953014), ('▁만큼', 0.12990726453285786), ('▁', 0.22349800248720256), ('라이트', 0.09830084479983084), ('▁노', 0.18178246278122032), ('벨', 0.11910986314834256), ('스러운', 0.12781944987432617), ('▁', 0.17932865158557723), ('록', 0.1340485372761158), ('맨', 0.1467060261075386), ('▁파', 0.19345820789379223), ('생', 0.10132452028206249), ('작', 0.16590080699770265), ('▁P', 0.16842903456608102), ('▁', 0.28932877923077366), ('.', 0.01677530609461315), ('▁S', 0.12715694609866895), ('▁시', 0.15192928322234275), ('궁', 0.051131892745432395), ('창', 0.07979307703115045), ('아', 0.17192197490411534), ('▁', 0.2042136427223123), ('es', 0.01279608539874598), ('c', 0.10523346307151586), ('고', 0.06486445242310346), ('쳐', 0.02688007216524755), ('라', 0.13960996377167995), ('▁바로', -0.022735524029650914), ('꺼', 0.08019544108202802), ('지는', 0.10435592099751799), ('거', 0.012060127698876287), ('▁', 0.16094690220988844), ('[UNK]', -0.008607468073490106), ('에', 0.10235450218670285), ('▁당황', -0.23958663246096798), ('했다', -0.15960428463843898), ('[SEP]', 0.0)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (0.63)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>4.94</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁평가                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁라                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아트                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁노                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 벨                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁소설                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁원                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 작                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 인                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁만큼                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 라이트                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁노                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 벨                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 스러운                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 록                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 맨                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁파                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 생                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 작                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁P                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁S                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁시                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 궁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 창                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 아                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> es                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> c                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 고                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 쳐                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 라                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁바로                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 꺼                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 지는                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 거                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [UNK]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 에                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁당황                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 했다                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "원문 :  그래픽이나 스토리 등이 맘에 들어서 구입했지만 멀미 때문에 환불해버린 게임 너무 아쉽다.. 왜 하필 멀미가 심하게 나서 엉엉\n",
      "속성 :  [('[CLS]', 0.0), ('▁그래픽', 0.014662971691584276), ('이나', -0.04924667887966248), ('▁스토리', 0.12294806545260335), ('▁등이', -0.009152429436063706), ('▁', -0.07457113636817246), ('맘', 0.016511868655893186), ('에', 0.002269354236368082), ('▁들어서', -0.02078661128180815), ('▁구입', -0.016198059583196804), ('했지만', -0.05427416763961263), ('▁', -0.03515685277640528), ('멀', 0.05564329690212023), ('미', -0.02401871279144652), ('▁때문에', -0.06638751707357127), ('▁환', 0.05703200244503825), ('불', 0.02057464575982131), ('해', -0.013759801645980008), ('버린', 0.0518167596907817), ('▁게임', 0.06893015080385166), ('▁너무', 0.06480176126126322), ('▁아', 0.021138495139964925), ('쉽', 0.01997744534545552), ('다', 0.013188131180738874), ('▁', -0.06770745654743615), ('.', -0.07198704425752317), ('▁', -0.03475094873590795), ('.', -0.04929883792568332), ('▁왜', 0.025221859995098662), ('▁하', 0.0039057011823294234), ('필', -0.015573069133991027), ('▁', -0.020896395435556596), ('멀', 0.10116043734138638), ('미', -0.05047297528774739), ('가', 0.12969500918526367), ('▁심', 0.03227286024565222), ('하게', -0.0173628292157202), ('▁나서', -0.13228051702055243), ('▁', 0.32434396417157874), ('엉', 0.11010313435914869), ('엉', -0.8754108819717141), ('[SEP]', 0.0)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (0.55)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>-0.44</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁그래픽                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 이나                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁스토리                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁등이                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 맘                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 에                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁들어서                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁구입                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 했지만                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 멀                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 미                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁때문에                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁환                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 불                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 해                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 버린                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁게임                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁너무                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁아                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 쉽                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 다                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁왜                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁하                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 필                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 멀                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 미                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 가                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁심                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 하게                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁나서                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 엉                    </font></mark><mark style=\"background-color: hsl(0, 75%, 65%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 엉                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "원문 :  한 2시간한것 같은데, 별로 재미없네요.\n",
      "속성 :  [('[CLS]', 0.0), ('▁한', 0.4297943730909265), ('▁2', 0.10023044066267092), ('시간', 0.01757563005876183), ('한', 0.10044026275236981), ('것', 0.004847511314888904), ('▁같은', -0.029694965908774833), ('데', 0.006042106015344449), ('▁', 0.291424289826742), (',', 0.04130916102592156), ('▁', 0.20343751447132413), ('별로', 0.01204394379571398), ('▁재미', -0.604816907668665), ('없', 0.5061397982122249), ('네요', 0.09065194880521597), ('▁', 0.17582509541274224), ('.', 0.06791200601846396), ('[SEP]', 0.0)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (0.58)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>1.41</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁한                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁2                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 시간                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 한                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 것                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁같은                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 데                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 별로                    </font></mark><mark style=\"background-color: hsl(0, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁재미                    </font></mark><mark style=\"background-color: hsl(120, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 없                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 네요                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> .                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "원문 :  관성이 무지막지해서 적응하기 힘들다\n",
      "속성 :  [('[CLS]', 0.0), ('▁관', 0.5214412695253645), ('성이', 0.06181360402198399), ('▁무', 0.14166413147442725), ('지', 0.08346689049068128), ('막', -0.07832419547468009), ('지', -0.07805181512956372), ('해서', -0.06687511065761013), ('▁적응', -0.10385955871835273), ('하기', -0.3372939646819779), ('▁힘들', -0.3416231186167121), ('다', 0.6627844334701084), ('[SEP]', 0.0)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (0.50)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>0.47</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁관                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 성이                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁무                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 지                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 막                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 지                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 해서                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁적응                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 하기                    </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁힘들                    </font></mark><mark style=\"background-color: hsl(120, 75%, 67%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 다                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "원문 :  잡것들 때문에 못해먹겠네\n",
      "속성 :  [('[CLS]', 0.0), ('▁잡', 0.11122447996399709), ('것', 0.018114984463814685), ('들', 0.05110504482185878), ('▁때문에', 0.07113183470436056), ('▁못해', -0.05867775995997601), ('먹', 0.16672651675552438), ('겠', 0.6142072085796776), ('네', -0.7557368542722865), ('[SEP]', 0.0)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (0.56)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>0.22</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁잡                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 것                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 들                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁때문에                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ▁못해                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 먹                    </font></mark><mark style=\"background-color: hsl(120, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 겠                    </font></mark><mark style=\"background-color: hsl(0, 75%, 70%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> 네                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "false_negative_sample = false_negative['sentence'].sample(n=5, random_state=42).reset_index(drop=True)\n",
    "\n",
    "for i in range(len(false_negative_sample)):\n",
    "    text = false_negative_sample[i]\n",
    "    print('원문 : ', text)\n",
    "\n",
    "    word_attributions = cls_explainer(text)\n",
    "    print('속성 : ', word_attributions)\n",
    "    cls_explainer.visualize(\"false_negative.html\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
